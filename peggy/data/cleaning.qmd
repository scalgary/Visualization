---
title: "Peggy"
format: html
---

```{python}
import os
os.listdir()
```

```{python}
import pandas as pd
df_raw = pd.read_csv('raw_peggy_DONNEES_ILP.csv')

# Afficher les premières lignes pour vérifier
df_raw.head()
df_raw.shape
```

# remove empty lines
```{python}
df_raw = df_raw.dropna(how='all')
df_raw.shape
```

# gere months
```{python}
df_raw['Année'].value_counts(dropna=False)
df_raw = df_raw.copy()

# Maintenant vous pouvez modifier sans warning
df_raw['Année'] = df_raw['Année'].astype(int)
col = 'Mois'
df_raw[col].value_counts(dropna=False)

# Dictionnaire de mapping pour tous les mois
mois_mapping = {
    'JANVIER': '01-Janvier',
    'FÉVRIER': '02-Février',
    'MARS': '03-Mars',
    'AVRIL': '04-Avril',
    'MAI': '05-Mai',
    'JUIN': '06-Juin',
    'JUILLET': '07-Juillet',
    'AOUT': '08-Août',
    'SEPTEMBRE': '09-Septembre',
    'OCTOBRE': '10-Octobre',
    'NOVEMBRE': '11-Novembre',
    'DECEMBRE': '12-Décembre',
    '11-Nov': '11-Novembre',
    '10-Oct': '10-Octobre',
    '12-Dec': '12-Décembre'
}

# Appliquer le mapping

df_raw['Mois'] = df_raw['Mois'].str.strip().replace(mois_mapping)
col = 'Mois'
df_raw[col].value_counts(dropna=False)
```


# drop some columns
```{python}
df_raw.drop(['Nom','Prénom','Demande','Unnamed: 3','SELAS'], axis=1, inplace=True)
```

# 3 types de variables
keep_float -> easy one no issue
keep_easy_clean -> few values just remove <
```{python}
keep_float = ['Ferritine (µg/L)','LBP (µg/mL)','Vitamine D (ng/mL)']
keep_easy_clean = ['Homocystéine (µmol/L)','TSH (mUI/L)']
```


 # examen 

```{python}

for col in keep_easy_clean:
    a = df_raw.filter([col])
    col_data = pd.to_numeric(df_raw[col], errors='coerce')
    print(col_data.min())
    print(col_data.max())
    print(col_data.count())
```
 



```{python}
def voir_valeurs_problematiques(df, nom_colonne):
    """Voir quelles valeurs spécifiques ne peuvent pas être converties avec leur nombre d'occurrences"""
    original = df[nom_colonne].dropna()
    converti = pd.to_numeric(df[nom_colonne], errors='coerce')

    # Identifier les index où la conversion a échoué
    mask_echec = converti.isna() & original.notna()
    valeurs_problematiques = df.loc[mask_echec, nom_colonne]

    # Compter les occurrences de chaque valeur problématique
    counts_problematiques = valeurs_problematiques.value_counts()

    print(f"Valeurs non-convertibles dans '{nom_colonne}' avec leurs occurrences:")
    print(counts_problematiques)
    print(f"Nombre total d'occurrences: {counts_problematiques.sum()} {valeurs_problematiques.unique()}")
    print(f"Nombre de valeurs uniques problématiques: {len(counts_problematiques)}")

    return counts_problematiques
```


```{python}
voir_valeurs_problematiques(df_raw,'Homocystéine (µmol/L)')
voir_valeurs_problematiques(df_raw,'TSH (mUI/L)')

```


```{python}
keep_float = ['Ferritine (µg/L)','LBP (µg/mL)','Vitamine D (ng/mL)']
keep_easy_clean = ['Homocystéine (µmol/L)','TSH (mUI/L)']

df = df_raw.copy()
for col in keep_easy_clean:
  df[col] = df[col].str.replace(',','.')
  df[col] = df[col].str.replace('<','')
  df[col] = pd.to_numeric(df[col], errors='coerce')

for col in keep_easy_clean + keep_float:
  a = df.filter([col])
  col_data = pd.to_numeric(df[col], errors='coerce')
  print(col_data.min())
  print(col_data.max())
  print(col_data.count())

```

3 - Ac anti-LDL oxydés (U/L)
4 - Homa
5 - PCR-US (mg/L)


```{python}
col = 'Homa'
voir_valeurs_problematiques(df,col)
df[col] = pd.to_numeric(df[col], errors='coerce')

df[col].value_counts(dropna=False)
df = df.dropna(subset = [col])
df.shape
```



```{python}
col = 'Ac anti-LDL oxydés (U/L)'
voir_valeurs_problematiques(df,col)

```

'Ac anti-LDL oxydés (U/L)'
```{python}
import numpy as np
col = 'Ac anti-LDL oxydés (U/L)'

conditions = [
    df[col] == '< 48',
    df[col] == '<48',
    df[col] == '< 37',
    df[col] == '> 1100',
    df[col] == '>1100'
]
choices = [30, 30, 30, 1210, 1210]

# Keep original score if none of the conditions match
df[col] = np.select(conditions, choices, default=df[col])
df[col] = pd.to_numeric(df[col], errors='coerce')
df = df[df[col] > 20]
```

'PCR-US (mg/L)'
```{python}
col =  'PCR-US (mg/L)'
voir_valeurs_problematiques(df,col)
col_data = pd.to_numeric(df[col], errors='coerce')
col_data.min()


conditions = [
    df[col] == '< 0,4'
]
choices = [0.35]

# Keep original score if none of the conditions match
df[col] = np.select(conditions, choices, default=df[col])
df[col] = pd.to_numeric(df[col], errors='coerce')


```


```{python}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import squarify  # pip install squarify


# Method 1: Create bins for both variables and count observations
def create_treemap_from_quantitative(df, var1, var2, bins1=5, bins2=5):
    """
    Create treemap from 2 quantitative variables by binning them
    """
    # Create bins for both variables
    df_copy = df.copy()
    df_copy[f'{var1}_bin'] = pd.cut(df_copy[var1], bins=bins1, precision=0)
    df_copy[f'{var2}_bin'] = pd.cut(df_copy[var2], bins=bins2, precision=0)
    
    # Count observations in each combination
    counts = df_copy.groupby([f'{var1}_bin', f'{var2}_bin']).size().reset_index(name='count')
    
    # Create labels combining both variables
    counts['label'] = (counts[f'{var1}_bin'].astype(str) + '\n' + 
                      counts[f'{var2}_bin'].astype(str) + '\n' + 
                      'n=' + counts['count'].astype(str))
    
    # Remove empty bins
    counts = counts[counts['count'] > 0]
    
    return counts
```

```{python}
# Vos 5 variables
variables = [
 'LBP (µg/mL)',
 'Homa']
# Create treemap data
treemap_data = create_treemap_from_quantitative(df,  'LBP (µg/mL)', 'Homa', bins1=15, bins2=15)
treemap_data
treemap_data.to_csv(f'find_rules_{datetime.now().strftime('%Y-%m-%d')}.csv')
```
```{python}


condition = (df['LBP (µg/mL)'] >= 11) &  (df['Homa'] < 8)

df_filter = df[~condition]
df = df_filter.copy()
df.shape
```


```{python}
df.to_csv(f'clean_data_{datetime.now().strftime('%Y-%m-%d')}.csv')
df.to_csv(f'clean_data.csv')

```